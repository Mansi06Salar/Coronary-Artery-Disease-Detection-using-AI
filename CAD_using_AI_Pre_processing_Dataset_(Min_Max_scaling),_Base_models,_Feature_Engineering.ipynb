{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mansi06Salar/Coronary-Artery-Disease-Detection-using-AI/blob/main/CAD_using_AI_Pre_processing_Dataset_(Min_Max_scaling)%2C_Base_models%2C_Feature_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "```\n",
        "\n",
        "**Basic Pre-processing**"
      ],
      "metadata": {
        "id": "mdmhbUcxhudV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder"
      ],
      "metadata": {
        "id": "c__R518rSdXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"CAD.csv\")\n",
        "\n",
        "print(\"Initial Dataset Shape:\", df.shape)\n",
        "print(\"Missing Values Before Processing:\\n\", df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjG3109pSf9a",
        "outputId": "7b0426e3-7fb9-4df3-8713-ef767c096001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Dataset Shape: (303, 55)\n",
            "Missing Values Before Processing:\n",
            " Age                      0\n",
            "Weight                   0\n",
            "Length                   0\n",
            "Sex                      0\n",
            "BMI                      0\n",
            "DM                       0\n",
            "HTN                      0\n",
            "Current Smoker           0\n",
            "EX-Smoker                0\n",
            "FH                       0\n",
            "Obesity                  0\n",
            "CRF                      0\n",
            "CVA                      0\n",
            "Airway disease           0\n",
            "Thyroid Disease          0\n",
            "CHF                      0\n",
            "DLP                      0\n",
            "BP                       0\n",
            "PR                       0\n",
            "Edema                    0\n",
            "Weak Peripheral Pulse    0\n",
            "Lung rales               0\n",
            "Systolic Murmur          0\n",
            "Diastolic Murmur         0\n",
            "Typical Chest Pain       0\n",
            "Dyspnea                  0\n",
            "Function Class           0\n",
            "Atypical                 0\n",
            "Nonanginal               0\n",
            "Exertional CP            0\n",
            "LowTH Ang                0\n",
            "Q Wave                   0\n",
            "St Elevation             0\n",
            "St Depression            0\n",
            "Tinversion               0\n",
            "LVH                      0\n",
            "Poor R Progression       0\n",
            "FBS                      0\n",
            "CR                       0\n",
            "TG                       0\n",
            "LDL                      0\n",
            "HDL                      0\n",
            "BUN                      0\n",
            "ESR                      0\n",
            "HB                       0\n",
            "K                        0\n",
            "Na                       0\n",
            "WBC                      0\n",
            "Lymph                    0\n",
            "Neut                     0\n",
            "PLT                      0\n",
            "EF-TTE                   0\n",
            "Region RWMA              0\n",
            "VHD                      0\n",
            "Cath                     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=[\"Exertional CP\"], inplace=True)\n",
        "print(\"Dropped column: Exertional CP\")\n",
        "\n",
        "df.rename(columns={\"Length\": \"Height\", \"Cath\": \"CAD\"}, inplace=True)\n",
        "print(\"Renamed columns: Length → Height, Cath → CAD\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7RiLp2SSmmH",
        "outputId": "dfc5d8a9-d663-4bc3-b64f-07bd72821dce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropped column: Exertional CP\n",
            "Renamed columns: Length → Height, Cath → CAD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sex'] = df['Sex'].replace({'Fmale': 'Female'})\n",
        "df['Sex'] = df['Sex'].map({'Male': 1, 'Female': 0})\n",
        "\n",
        "df['CAD'] = df['CAD'].map({'Cad': 1, 'Normal': 0})\n",
        "print(\"Encoded Target Variable CAD\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX6sbT5USpxU",
        "outputId": "edf5e45f-1ebd-465d-84a4-c901d36071a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Target Variable CAD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "binary_columns = [\n",
        "    'Obesity', 'CRF', 'CVA', 'Airway disease', 'Thyroid Disease',\n",
        "    'CHF', 'DLP', 'Weak Peripheral Pulse', 'Lung rales', 'Systolic Murmur', 'Diastolic Murmur',\n",
        "    'Dyspnea', 'Atypical', 'Nonanginal', 'LowTH Ang', 'LVH', 'Poor R Progression'\n",
        "]"
      ],
      "metadata": {
        "id": "azEB91_uSrfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "for col in binary_columns:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "    print(f\"Label Encoded Column: {col}\")\n",
        "\n",
        "df['VHD'] = df['VHD'].map({'N': 0, 'mild': 1, 'Moderate': 2, 'Severe': 3})\n",
        "print(\"Applied Ordinal Encoding to VHD\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wW4AGSMtSwja",
        "outputId": "2f8029da-3523-46a6-e693-da99c0cd702c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Encoded Column: Obesity\n",
            "Label Encoded Column: CRF\n",
            "Label Encoded Column: CVA\n",
            "Label Encoded Column: Airway disease\n",
            "Label Encoded Column: Thyroid Disease\n",
            "Label Encoded Column: CHF\n",
            "Label Encoded Column: DLP\n",
            "Label Encoded Column: Weak Peripheral Pulse\n",
            "Label Encoded Column: Lung rales\n",
            "Label Encoded Column: Systolic Murmur\n",
            "Label Encoded Column: Diastolic Murmur\n",
            "Label Encoded Column: Dyspnea\n",
            "Label Encoded Column: Atypical\n",
            "Label Encoded Column: Nonanginal\n",
            "Label Encoded Column: LowTH Ang\n",
            "Label Encoded Column: LVH\n",
            "Label Encoded Column: Poor R Progression\n",
            "Applied Ordinal Encoding to VHD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "num_cols.remove(\"CAD\")\n",
        "num_cols.remove(\"VHD\")"
      ],
      "metadata": {
        "id": "a6dwcx4wSy1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PzOPFQsdA5d",
        "outputId": "27d62df1-577e-426d-98a2-0ede7a8fefad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min-Max Scaling applied to: ['Age', 'Weight', 'Height', 'Sex', 'BMI', 'DM', 'HTN', 'Current Smoker', 'EX-Smoker', 'FH', 'Obesity', 'CRF', 'CVA', 'Airway disease', 'Thyroid Disease', 'CHF', 'DLP', 'BP', 'PR', 'Edema', 'Weak Peripheral Pulse', 'Lung rales', 'Systolic Murmur', 'Diastolic Murmur', 'Typical Chest Pain', 'Dyspnea', 'Function Class', 'Atypical', 'Nonanginal', 'LowTH Ang', 'Q Wave', 'St Elevation', 'St Depression', 'Tinversion', 'LVH', 'Poor R Progression', 'FBS', 'CR', 'TG', 'LDL', 'HDL', 'BUN', 'ESR', 'HB', 'K', 'Na', 'WBC', 'Lymph', 'Neut', 'PLT', 'EF-TTE', 'Region RWMA']\n",
            "Final Dataset Shape: (303, 54)\n",
            "Missing Values After Processing:\n",
            " Age                      0\n",
            "Weight                   0\n",
            "Height                   0\n",
            "Sex                      0\n",
            "BMI                      0\n",
            "DM                       0\n",
            "HTN                      0\n",
            "Current Smoker           0\n",
            "EX-Smoker                0\n",
            "FH                       0\n",
            "Obesity                  0\n",
            "CRF                      0\n",
            "CVA                      0\n",
            "Airway disease           0\n",
            "Thyroid Disease          0\n",
            "CHF                      0\n",
            "DLP                      0\n",
            "BP                       0\n",
            "PR                       0\n",
            "Edema                    0\n",
            "Weak Peripheral Pulse    0\n",
            "Lung rales               0\n",
            "Systolic Murmur          0\n",
            "Diastolic Murmur         0\n",
            "Typical Chest Pain       0\n",
            "Dyspnea                  0\n",
            "Function Class           0\n",
            "Atypical                 0\n",
            "Nonanginal               0\n",
            "LowTH Ang                0\n",
            "Q Wave                   0\n",
            "St Elevation             0\n",
            "St Depression            0\n",
            "Tinversion               0\n",
            "LVH                      0\n",
            "Poor R Progression       0\n",
            "FBS                      0\n",
            "CR                       0\n",
            "TG                       0\n",
            "LDL                      0\n",
            "HDL                      0\n",
            "BUN                      0\n",
            "ESR                      0\n",
            "HB                       0\n",
            "K                        0\n",
            "Na                       0\n",
            "WBC                      0\n",
            "Lymph                    0\n",
            "Neut                     0\n",
            "PLT                      0\n",
            "EF-TTE                   0\n",
            "Region RWMA              0\n",
            "VHD                      0\n",
            "CAD                      0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "scaler = MinMaxScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "print(\"Min-Max Scaling applied to:\", num_cols)\n",
        "\n",
        "print(\"Final Dataset Shape:\", df.shape)\n",
        "print(\"Missing Values After Processing:\\n\", df.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"PreProcessed_Dataset_MinMax.csv\", index=False)\n",
        "print(\"Preprocessing Complete.\")"
      ],
      "metadata": {
        "id": "LHuwW8ljS33D",
        "outputId": "9cb23d26-076c-4665-dd73-a1700bc0f169",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "wSXMcyycjiU_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "**Applying 10 ML model**"
      ],
      "metadata": {
        "id": "owOhVrYHiE8q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "_hLA-DQOiwzn"
      }
    },
    {
      "source": [
        "!pip install catboost"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ-2JOqpCtT5",
        "outputId": "1a0c8971-d23e-4744-fbe2-61c570c431f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.24.3)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,classification_report\n",
        ")\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "3Um-c6SsCeI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"PreProcessed_Dataset_MinMax.csv\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ac-LEhtwCfoN",
        "outputId": "0ebca0c9-5109-4a3e-ce7b-6a7677888804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Age    Weight    Height  Sex       BMI   DM  HTN  Current Smoker  \\\n",
            "0  0.410714  0.583333  0.729167  1.0  0.494721  0.0  1.0             1.0   \n",
            "1  0.660714  0.305556  0.354167  0.0  0.451314  0.0  1.0             0.0   \n",
            "2  0.428571  0.083333  0.500000  1.0  0.086105  0.0  0.0             1.0   \n",
            "3  0.642857  0.263889  0.375000  0.0  0.382846  0.0  1.0             0.0   \n",
            "4  0.357143  0.541667  0.270833  0.0  0.836058  0.0  1.0             0.0   \n",
            "\n",
            "   EX-Smoker   FH  ...         K        Na       WBC     Lymph      Neut  \\\n",
            "0        0.0  0.0  ...  0.472222  0.464286  0.139860  0.603774  0.350877   \n",
            "1        0.0  0.0  ...  0.472222  1.000000  0.279720  0.584906  0.403509   \n",
            "2        0.0  0.0  ...  0.472222  0.392857  0.258741  0.584906  0.491228   \n",
            "3        0.0  0.0  ...  0.388889  0.500000  0.650350  0.207547  0.701754   \n",
            "4        0.0  0.0  ...  0.277778  0.428571  0.384615  0.905660  0.122807   \n",
            "\n",
            "        PLT    EF-TTE  Region RWMA  VHD  CAD  \n",
            "0  0.329149  0.777778          0.0    0    1  \n",
            "1  0.195258  0.555556          1.0    0    1  \n",
            "2  0.285914  0.555556          0.5    1    1  \n",
            "3  1.000000  0.888889          0.0    3    0  \n",
            "4  0.347280  0.777778          0.0    3    0  \n",
            "\n",
            "[5 rows x 54 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fix LightGBM warning: Remove spaces from feature names\n",
        "df.columns = [col.replace(\" \", \"_\") for col in df.columns]"
      ],
      "metadata": {
        "id": "W8-5vnFWCjTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['CAD'])\n",
        "y = df['CAD']"
      ],
      "metadata": {
        "id": "sXvmPOoiCktU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Class Distribution BEFORE SMOTE:\", Counter(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cf75pyfUCnLs",
        "outputId": "0820d2ef-d28b-4808-9fc9-5856aaf8aebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution BEFORE SMOTE: Counter({1: 216, 0: 87})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smote_applied = False\n",
        "imbalance_threshold = 0.6  #SMOTE if any class is <40% of the largest class\n",
        "\n",
        "class_counts = Counter(y)\n",
        "minority_class = min(class_counts, key=class_counts.get)\n",
        "majority_class = max(class_counts, key=class_counts.get)\n",
        "imbalance_ratio = class_counts[minority_class] / class_counts[majority_class]\n",
        "\n",
        "if imbalance_ratio < imbalance_threshold:\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X, y = smote.fit_resample(X, y)\n",
        "    smote_applied = True\n",
        "\n",
        "print(\"Class Distribution AFTER SMOTE:\", Counter(y) if smote_applied else \"SMOTE Not Applied\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOwqB6pvCre4",
        "outputId": "dd18c899-d0ac-40e2-a6b1-3cfa6c19499a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution AFTER SMOTE: Counter({1: 216, 0: 216})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "WboLsRjfCs8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(max_depth=10),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=10),\n",
        "    \"XGBoost\": XGBClassifier(eval_metric='logloss', use_label_encoder=False),\n",
        "    \"LightGBM\": LGBMClassifier(max_depth=10, min_data_in_leaf=5),\n",
        "    \"CatBoost\": CatBoostClassifier(verbose=0),\n",
        "    \"AdaBoost\": AdaBoostClassifier(n_estimators=50),\n",
        "    \"SVM\": SVC(probability=True),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"Naïve Bayes\": GaussianNB()\n",
        "}"
      ],
      "metadata": {
        "id": "B4Ng7qKyCulG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, model in models.items():\n",
        "    try:\n",
        "        print(f\"\\n================== {name} ==================\")\n",
        "        start_time = time.time()\n",
        "        model.fit(X_train, y_train)\n",
        "        train_time = time.time() - start_time\n",
        "\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Check if predict_proba is available\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            y_prob = model.predict_proba(X_test)[:, 1]\n",
        "        else:\n",
        "            y_prob = None\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, average=\"binary\", zero_division=1)\n",
        "        recall = recall_score(y_test, y_pred, average=\"binary\")\n",
        "        f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
        "        auc = roc_auc_score(y_test, y_prob) if y_prob is not None else np.nan\n",
        "\n",
        "        results.append([name, accuracy, precision, recall, f1, auc, train_time])\n",
        "\n",
        "        # Print detailed classification report\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(y_test, y_pred, zero_division=1))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error training {name}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr7D904I77w2",
        "outputId": "cbe88756-c5bc-48ed-ab38-cb2653364ee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================== Logistic Regression ==================\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.91      0.90        44\n",
            "           1       0.90      0.88      0.89        43\n",
            "\n",
            "    accuracy                           0.90        87\n",
            "   macro avg       0.90      0.90      0.90        87\n",
            "weighted avg       0.90      0.90      0.90        87\n",
            "\n",
            "\n",
            "================== Decision Tree ==================\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.84      0.87        44\n",
            "           1       0.85      0.91      0.88        43\n",
            "\n",
            "    accuracy                           0.87        87\n",
            "   macro avg       0.88      0.87      0.87        87\n",
            "weighted avg       0.88      0.87      0.87        87\n",
            "\n",
            "\n",
            "================== Random Forest ==================\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.95      0.92        44\n",
            "           1       0.95      0.88      0.92        43\n",
            "\n",
            "    accuracy                           0.92        87\n",
            "   macro avg       0.92      0.92      0.92        87\n",
            "weighted avg       0.92      0.92      0.92        87\n",
            "\n",
            "\n",
            "================== XGBoost ==================\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.93      0.92        44\n",
            "           1       0.93      0.91      0.92        43\n",
            "\n",
            "    accuracy                           0.92        87\n",
            "   macro avg       0.92      0.92      0.92        87\n",
            "weighted avg       0.92      0.92      0.92        87\n",
            "\n",
            "\n",
            "================== LightGBM ==================\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Info] Number of positive: 173, number of negative: 172\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000339 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1453\n",
            "[LightGBM] [Info] Number of data points in the train set: 345, number of used features: 51\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501449 -> initscore=0.005797\n",
            "[LightGBM] [Info] Start training from score 0.005797\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:40:34] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87        44\n",
            "           1       0.90      0.81      0.85        43\n",
            "\n",
            "    accuracy                           0.86        87\n",
            "   macro avg       0.87      0.86      0.86        87\n",
            "weighted avg       0.87      0.86      0.86        87\n",
            "\n",
            "\n",
            "================== CatBoost ==================\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.93      0.91        44\n",
            "           1       0.93      0.88      0.90        43\n",
            "\n",
            "    accuracy                           0.91        87\n",
            "   macro avg       0.91      0.91      0.91        87\n",
            "weighted avg       0.91      0.91      0.91        87\n",
            "\n",
            "\n",
            "================== AdaBoost ==================\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88        44\n",
            "           1       0.90      0.84      0.87        43\n",
            "\n",
            "    accuracy                           0.87        87\n",
            "   macro avg       0.88      0.87      0.87        87\n",
            "weighted avg       0.88      0.87      0.87        87\n",
            "\n",
            "\n",
            "================== SVM ==================\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.93      0.91        44\n",
            "           1       0.93      0.88      0.90        43\n",
            "\n",
            "    accuracy                           0.91        87\n",
            "   macro avg       0.91      0.91      0.91        87\n",
            "weighted avg       0.91      0.91      0.91        87\n",
            "\n",
            "\n",
            "================== KNN ==================\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.98      0.87        44\n",
            "           1       0.97      0.72      0.83        43\n",
            "\n",
            "    accuracy                           0.85        87\n",
            "   macro avg       0.88      0.85      0.85        87\n",
            "weighted avg       0.87      0.85      0.85        87\n",
            "\n",
            "\n",
            "================== Naïve Bayes ==================\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.98      0.71        44\n",
            "           1       0.90      0.21      0.34        43\n",
            "\n",
            "    accuracy                           0.60        87\n",
            "   macro avg       0.73      0.59      0.53        87\n",
            "weighted avg       0.73      0.60      0.53        87\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame for summary\n",
        "metrics_df = pd.DataFrame(\n",
        "    results,\n",
        "    columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"AUROC\", \"Train Time\"]\n",
        ")"
      ],
      "metadata": {
        "id": "xljZmcBF7_dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort by Accuracy descending\n",
        "metrics_df = metrics_df.sort_values(by=\"Accuracy\", ascending=False)\n",
        "\n",
        "# Remove duplicates based on Model name, keep the first (highest accuracy) one\n",
        "metrics_df = metrics_df.drop_duplicates(subset=[\"Model\"], keep=\"first\").reset_index(drop=True)\n",
        "\n",
        "# Limit to top 10 models\n",
        "metrics_df = metrics_df.head(10)"
      ],
      "metadata": {
        "id": "l77dtVG18Bz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n================== Model Performance Summary ==================\")\n",
        "print(metrics_df.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eid5wQMU6iHd",
        "outputId": "f4fb1873-7817-4a87-e127-41baeb13f44a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================== Model Performance Summary ==================\n",
            "              Model  Accuracy  Precision   Recall  F1 Score    AUROC  Train Time\n",
            "            XGBoost  0.919540   0.928571 0.906977  0.917647 0.979387    1.576789\n",
            "      Random Forest  0.919540   0.950000 0.883721  0.915663 0.978594    0.251024\n",
            "                SVM  0.908046   0.926829 0.883721  0.904762 0.956131    0.025559\n",
            "           CatBoost  0.908046   0.926829 0.883721  0.904762 0.974101    5.065156\n",
            "Logistic Regression  0.896552   0.904762 0.883721  0.894118 0.949789    0.095062\n",
            "      Decision Tree  0.896552   0.869565 0.930233  0.898876 0.894556    0.029436\n",
            "           AdaBoost  0.873563   0.900000 0.837209  0.867470 0.958245    0.150244\n",
            "           LightGBM  0.862069   0.897436 0.813953  0.853659 0.969345    0.127442\n",
            "                KNN  0.850575   0.968750 0.720930  0.826667 0.869450    0.002869\n",
            "        Naïve Bayes  0.597701   0.900000 0.209302  0.339623 0.887685    0.003727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "q8rajosgj5ir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Feature* Engineering"
      ],
      "metadata": {
        "id": "-CyTY0m3i5-6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "d6SWxHQ5jPkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kgywzCTNjRSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.feature_selection import RFE, mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "VPWxcnT4Tqjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"PreProcessed_Dataset_MinMax.csv\")\n",
        "df.columns = [col.replace(\" \", \"_\") for col in df.columns]"
      ],
      "metadata": {
        "id": "aLzUod7qTvB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['CAD'])\n",
        "y = df['CAD']"
      ],
      "metadata": {
        "id": "k9Pl19O0TwSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Before Feature Selection: {X.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t4abDc4Txo9",
        "outputId": "a8f9f0e0-912a-4ad2-80bb-358afe5f388c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Feature Selection: (303, 53)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost Feature Importance\n",
        "xgb_model = XGBClassifier(eval_metric='logloss', random_state=42)\n",
        "xgb_model.fit(X, y)\n",
        "xgb_importance = pd.DataFrame({\"Feature\": X.columns, \"XGB_Importance\": xgb_model.feature_importances_})"
      ],
      "metadata": {
        "id": "QOFRGXUtTzan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recursive Feature Elimination (RFE) with RandomForest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rfe = RFE(rf_model, n_features_to_select=15)\n",
        "rfe.fit(X, y)\n",
        "rfe_features = X.columns[rfe.support_]"
      ],
      "metadata": {
        "id": "SQpLv-ANT2Zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mutual Information Scores\n",
        "mi_scores = mutual_info_classif(X, y)\n",
        "mi_importance = pd.DataFrame({\"Feature\": X.columns, \"MI_Score\": mi_scores})"
      ],
      "metadata": {
        "id": "b1dxzvf8T4St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hybrid Feature Selection\n",
        "feature_scores = xgb_importance.merge(mi_importance, on=\"Feature\")\n",
        "feature_scores[\"Final_Score\"] = (feature_scores[\"XGB_Importance\"] * 0.5 + feature_scores[\"MI_Score\"] * 0.3)\n",
        "top_features = feature_scores.nlargest(15, \"Final_Score\")[\"Feature\"].tolist()\n",
        "final_features = list(set(top_features + list(rfe_features)))"
      ],
      "metadata": {
        "id": "R3UcL9PLT5tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BtIdEvCTdvi"
      },
      "outputs": [],
      "source": [
        "X_reduced = X[final_features].copy()\n",
        "X_reduced.loc[:, 'CAD'] = y  #Fixing the SettingWithCopyWarning\n",
        "X_reduced.to_csv(\"Reduced_Dataset_Hybrid_Approach\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"After Feature Selection: {X_reduced.shape}\")\n",
        "print(f\"Hybrid Feature Selection Done. Final {len(final_features)} features saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQMPghLaT8u0",
        "outputId": "563d7407-005f-4189-c008-547531a634e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Feature Selection: (303, 24)\n",
            "Hybrid Feature Selection Done. Final 23 features saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Reduced_Dataset_Hybrid_Approach\") #NEW REDUCED DATASET OBTAINED"
      ],
      "metadata": {
        "id": "e6c2RRlJ-ysF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now applying 10 ML classifiers to the generated reduced dataset"
      ],
      "metadata": {
        "id": "QOmaeP_2_yxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = [col.replace(\" \", \"_\") for col in df.columns]\n",
        "\n",
        "X = df.drop(columns=['CAD'])\n",
        "y = df['CAD']\n",
        "print(\"Class Distribution BEFORE SMOTE:\", Counter(y))\n",
        "\n",
        "smote_applied = False\n",
        "imbalance_threshold = 0.6  #SMOTE if any class is <40% of the largest class\n",
        "\n",
        "class_counts = Counter(y)\n",
        "minority_class = min(class_counts, key=class_counts.get)\n",
        "majority_class = max(class_counts, key=class_counts.get)\n",
        "imbalance_ratio = class_counts[minority_class] / class_counts[majority_class]\n",
        "\n",
        "if imbalance_ratio < imbalance_threshold:\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X, y = smote.fit_resample(X, y)\n",
        "    smote_applied = True\n",
        "\n",
        "print(\"Class Distribution AFTER SMOTE:\", Counter(y) if smote_applied else \"SMOTE Not Applied\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIYUFGTP-8Cg",
        "outputId": "2dea5503-4261-4171-9f7b-b5cb7a78dc4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution BEFORE SMOTE: Counter({1: 216, 0: 87})\n",
            "Class Distribution AFTER SMOTE: Counter({1: 216, 0: 216})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for name, model in models.items():\n",
        "    try:\n",
        "        print(f\"\\n================== {name} ==================\")\n",
        "        start_time = time.time()\n",
        "        model.fit(X_train, y_train)\n",
        "        train_time = time.time() - start_time\n",
        "\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Check if predict_proba is available\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            y_prob = model.predict_proba(X_test)[:, 1]\n",
        "        else:\n",
        "            y_prob = None\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, average=\"binary\", zero_division=1)\n",
        "        recall = recall_score(y_test, y_pred, average=\"binary\")\n",
        "        f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
        "        auc = roc_auc_score(y_test, y_prob) if y_prob is not None else np.nan\n",
        "\n",
        "        results.append([name, accuracy, precision, recall, f1, auc, train_time])\n",
        "\n",
        "        # Print detailed classification report\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(y_test, y_pred, zero_division=1))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error training {name}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9H5pKSa_EmQ",
        "outputId": "738caa93-7acb-482a-ef39-804ae1f61e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================== Logistic Regression ==================\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89        44\n",
            "           1       0.88      0.88      0.88        43\n",
            "\n",
            "    accuracy                           0.89        87\n",
            "   macro avg       0.89      0.89      0.89        87\n",
            "weighted avg       0.89      0.89      0.89        87\n",
            "\n",
            "\n",
            "================== Decision Tree ==================\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.89      0.83        44\n",
            "           1       0.86      0.74      0.80        43\n",
            "\n",
            "    accuracy                           0.82        87\n",
            "   macro avg       0.82      0.82      0.81        87\n",
            "weighted avg       0.82      0.82      0.82        87\n",
            "\n",
            "\n",
            "================== Random Forest ==================\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.93      0.90        44\n",
            "           1       0.93      0.86      0.89        43\n",
            "\n",
            "    accuracy                           0.90        87\n",
            "   macro avg       0.90      0.90      0.90        87\n",
            "weighted avg       0.90      0.90      0.90        87\n",
            "\n",
            "\n",
            "================== XGBoost ==================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:43:41] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.95      0.94        44\n",
            "           1       0.95      0.93      0.94        43\n",
            "\n",
            "    accuracy                           0.94        87\n",
            "   macro avg       0.94      0.94      0.94        87\n",
            "weighted avg       0.94      0.94      0.94        87\n",
            "\n",
            "\n",
            "================== LightGBM ==================\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Info] Number of positive: 173, number of negative: 172\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000139 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 980\n",
            "[LightGBM] [Info] Number of data points in the train set: 345, number of used features: 23\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501449 -> initscore=0.005797\n",
            "[LightGBM] [Info] Start training from score 0.005797\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.93      0.90        44\n",
            "           1       0.93      0.86      0.89        43\n",
            "\n",
            "    accuracy                           0.90        87\n",
            "   macro avg       0.90      0.90      0.90        87\n",
            "weighted avg       0.90      0.90      0.90        87\n",
            "\n",
            "\n",
            "================== CatBoost ==================\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.93      0.92        44\n",
            "           1       0.93      0.91      0.92        43\n",
            "\n",
            "    accuracy                           0.92        87\n",
            "   macro avg       0.92      0.92      0.92        87\n",
            "weighted avg       0.92      0.92      0.92        87\n",
            "\n",
            "\n",
            "================== AdaBoost ==================\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93        44\n",
            "           1       0.93      0.93      0.93        43\n",
            "\n",
            "    accuracy                           0.93        87\n",
            "   macro avg       0.93      0.93      0.93        87\n",
            "weighted avg       0.93      0.93      0.93        87\n",
            "\n",
            "\n",
            "================== SVM ==================\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.84      0.86        44\n",
            "           1       0.84      0.88      0.86        43\n",
            "\n",
            "    accuracy                           0.86        87\n",
            "   macro avg       0.86      0.86      0.86        87\n",
            "weighted avg       0.86      0.86      0.86        87\n",
            "\n",
            "\n",
            "================== KNN ==================\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.89      0.84        44\n",
            "           1       0.87      0.77      0.81        43\n",
            "\n",
            "    accuracy                           0.83        87\n",
            "   macro avg       0.83      0.83      0.83        87\n",
            "weighted avg       0.83      0.83      0.83        87\n",
            "\n",
            "\n",
            "================== Naïve Bayes ==================\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89        44\n",
            "           1       0.88      0.88      0.88        43\n",
            "\n",
            "    accuracy                           0.89        87\n",
            "   macro avg       0.89      0.89      0.89        87\n",
            "weighted avg       0.89      0.89      0.89        87\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame for summary\n",
        "metrics_df = pd.DataFrame(\n",
        "    results,\n",
        "    columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"AUROC\", \"Train Time\"]\n",
        ")"
      ],
      "metadata": {
        "id": "SPo6mX02_V4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort by Accuracy descending\n",
        "metrics_df = metrics_df.sort_values(by=\"Accuracy\", ascending=False)\n",
        "\n",
        "# Remove duplicates based on Model name, keep the first (highest accuracy) one\n",
        "metrics_df = metrics_df.drop_duplicates(subset=[\"Model\"], keep=\"first\").reset_index(drop=True)\n",
        "\n",
        "# Limit to top 10 models\n",
        "metrics_df = metrics_df.head(10)"
      ],
      "metadata": {
        "id": "CH1WV7tx_WcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n================== Model Performance Summary ==================\")\n",
        "print(metrics_df.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR5hqHX6_ZkP",
        "outputId": "ff135ea4-9df1-4ebb-b4aa-18119485af04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================== Model Performance Summary ==================\n",
            "              Model  Accuracy  Precision   Recall  F1 Score    AUROC  Train Time\n",
            "            XGBoost  0.942529   0.952381 0.930233  0.941176 0.979915    0.752237\n",
            "           AdaBoost  0.931034   0.930233 0.930233  0.930233 0.969873    0.287196\n",
            "           CatBoost  0.919540   0.928571 0.906977  0.917647 0.974101    7.325948\n",
            "      Random Forest  0.896552   0.925000 0.860465  0.891566 0.970402    0.470626\n",
            "           LightGBM  0.896552   0.925000 0.860465  0.891566 0.964059    0.176407\n",
            "Logistic Regression  0.885057   0.883721 0.883721  0.883721 0.936575    0.013854\n",
            "        Naïve Bayes  0.885057   0.883721 0.883721  0.883721 0.950317    0.008999\n",
            "                SVM  0.862069   0.844444 0.883721  0.863636 0.939746    0.034225\n",
            "                KNN  0.827586   0.868421 0.767442  0.814815 0.914376    0.004976\n",
            "      Decision Tree  0.816092   0.864865 0.744186  0.800000 0.815275    0.018064\n"
          ]
        }
      ]
    }
  ]
}